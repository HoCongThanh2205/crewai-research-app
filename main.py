import requests
import time
import PyPDF2
import docx
import io
from crew import build_crew
from tasks import research_task, analysis_task, trend_task, content_task
from tools.google_sheets_writer import write_to_google_sheets

def read_pdf(file_stream):
    try:
        pdf_reader = PyPDF2.PdfReader(file_stream)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"Error reading PDF: {str(e)}"

def read_docx(file_stream):
    try:
        doc = docx.Document(file_stream)
        text = ""
        for para in doc.paragraphs:
            text += para.text + "\n"
        return text
    except Exception as e:
        return f"Error reading DOCX: {str(e)}"

def run_crew_process(topic: str, file_content: str = None, file_name: str = None):
    """
    Ch·∫°y to√†n b·ªô quy tr√¨nh CrewAI v√† c√°c tool t√≠ch h·ª£p.
    Tr·∫£ v·ªÅ dictionary ch·ª©a k·∫øt qu·∫£.
    """
    print(f"üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω ch·ªß ƒë·ªÅ: {topic}")
    
    # N·∫øu c√≥ file, c·∫≠p nh·∫≠t description c·ªßa research_task
    if file_content:
        print(f"üìÇ ƒê√£ nh·∫≠n file: {file_name}")
        research_task.description = f"""
        CONTEXT FROM UPLOADED FILE ({file_name}):
        {file_content[:20000]} # Limit 20k chars to avoid token limit
        
        TASK:
        1. Analyze the uploaded document content above carefully.
        2. Research the topic: "{topic}" using the Search Tool.
        3. Combine insights from the file AND external search results.
        
        Requirements:
        - Find the latest and most relevant information.
        - **CRITICAL**: Every piece of information MUST have a citation with a valid URL.
        - Format citations as: [Source Name](URL)
        - If you cannot find a URL, explicitly state that.
        - Neutral, factual tone.
        - Write in VIETNAMESE.
        """
    else:
        # Reset description n·∫øu kh√¥ng c√≥ file (ƒë·ªÉ tr√°nh l∆∞u state c≈©)
        research_task.description = f"""
        Research the topic: "{topic}" using the Search Tool.

        Requirements:
        - Find the latest and most relevant information.
        - **CRITICAL**: Every piece of information MUST have a citation with a valid URL.
        - Format citations as: [Source Name](URL)
        - If you cannot find a URL, explicitly state that.
        - Neutral, factual tone.
        - Write in VIETNAMESE.
        """

    crew = build_crew(topic)
    crew.kickoff()

    # üî• L·∫§Y OUTPUT G·ªêC ‚Äì KH√îNG B·ªä T√ìM T·∫ÆT
    research_output = research_task.output.raw
    analysis_output = analysis_task.output.raw
    trend_output = trend_task.output.raw
    content_output = content_task.output.raw

    # ========= 1Ô∏è‚É£ POST FORM-DATA =========
    upload_url = "https://tool.taivo.top/notebooklm/upload"

    def remove_non_bmp_characters(text):
        return ''.join(c for c in text if ord(c) <= 0xFFFF)

    def clean_output(text):
        """Lo·∫°i b·ªè c√°c d√≤ng log c·ªßa tool (Using tool, Parameters) kh·ªèi output"""
        lines = text.split('\n')
        cleaned_lines = []
        for line in lines:
            # Lo·∫°i b·ªè d√≤ng ch·ª©a log tool
            if "Using tool:" in line or "Parameters:" in line or "Using tool" in line:
                continue
            cleaned_lines.append(line)
        return '\n'.join(cleaned_lines).strip()

    # üî• L·∫§Y OUTPUT G·ªêC ‚Äì KH√îNG B·ªä T√ìM T·∫ÆT
    research_output = research_task.output.raw
    analysis_output = analysis_task.output.raw
    trend_output = clean_output(trend_task.output.raw) # Clean logs
    content_output = content_task.output.raw

    # Filter emojis/non-BMP chars for this specific API to avoid ChromeDriver error
    sanitized_content = remove_non_bmp_characters(content_output)

    form_data = {
        "text": sanitized_content,
        "prompt": "D·ª±a tr√™n to√†n b·ªô t√†i li·ªáu ƒë√£ t·∫£i l√™n, h√£y t·∫°o m·ªôt timeline"
    }

    try:
        upload_response = requests.post(
            upload_url,
            data=form_data,  # ‚Üê form-data
            timeout=30
        )
        print("Upload status:", upload_response.status_code)
        
        upload_json = upload_response.json()
        job_id = upload_json.get("job_id")
        
        timeline_result = None
        
        if job_id:
            print("‚úÖ job_id:", job_id)
            # ========= 2Ô∏è‚É£ ƒê·ª¢I X·ª¨ L√ù =========
            time.sleep(10)  # API n√†y x·ª≠ l√Ω kh√° l√¢u

            # ========= 3Ô∏è‚É£ GET RESULT =========
            result_url = f"https://tool.taivo.top/notebooklm/result/{job_id}"
            
            # Th·ª≠ t·ªëi ƒëa 10 l·∫ßn (100s)
            for _ in range(10):
                try:
                    result_response = requests.get(result_url, timeout=30)
                    result_json = result_response.json()
                    print("üì° RESULT:", result_json)

                    if result_json.get("status") == "running":
                        print("‚è≥ ƒêang x·ª≠ l√Ω... ƒë·ª£i 10 gi√¢y")
                        time.sleep(10)
                        continue
                    
                    # N·∫øu ƒë√£ xong
                    print("üéâ HO√ÄN TH√ÄNH TIMELINE")
                    timeline_result = result_json
                    break
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói khi check result: {e}")
                    time.sleep(5)
        else:
            print("‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c job_id cho Timeline")

    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói qu√° tr√¨nh t·∫°o Timeline: {e}")
        timeline_result = {"error": str(e)}

    # L·∫•y URL timeline (n·∫øu c√≥)
    timeline_url = ""
    if timeline_result:
        print(f"üîç DEBUG TIMELINE RESULT: {timeline_result}") # Debug
        if "result" in timeline_result:
            timeline_url = timeline_result["result"]
            print(f"‚úÖ FOUND TIMELINE URL: {timeline_url}")
        else:
            print("‚ö†Ô∏è Timeline result does not contain 'result' key")
    else:
        print("‚ö†Ô∏è No timeline result returned")

    # üî• L∆ØU T·∫†I PYTHON (KH√îNG QUA AGENT)
    try:
        sheets_status = write_to_google_sheets(
            topic=topic,
            research=research_output,
            analysis=analysis_output,
            trend=trend_output,
            content=content_output,
            timeline=timeline_url
        )
        print(f"‚úÖ ƒê√£ l∆∞u v√†o Google Sheets (Status: {sheets_status})")
    except Exception as e:
        print(f"‚ùå L·ªói l∆∞u Google Sheets: {e}")
        sheets_status = "Error"

    return {
        "topic": topic,
        "research": research_output,
        "analysis": analysis_output,
        "trend": trend_output,
        "content": content_output,
        "timeline": timeline_result,
        "timeline_url": timeline_url,
        "sheets_status": sheets_status
    }

if __name__ == "__main__":
    topic_input = input("Nh·∫≠p ch·ªß ƒë·ªÅ: ")
    run_crew_process(topic_input)
